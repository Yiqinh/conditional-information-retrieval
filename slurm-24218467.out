==========================================
SLURM_JOB_ID = 24218467
SLURM_JOB_NODELIST = a01-06
TMPDIR = /tmp/SLURM_24218467
==========================================
/spack/conda/miniconda3/23.10.0/bin/conda: line 3: import: command not found
/spack/conda/miniconda3/23.10.0/bin/conda: line 6: syntax error near unexpected token `sys.argv'
/spack/conda/miniconda3/23.10.0/bin/conda: line 6: `if len(sys.argv) > 1 and sys.argv[1].startswith('shell.') and sys.path and sys.path[0] == '':'
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: transformers in /home1/yh_739/.local/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (4.41.2)
Requirement already satisfied: torch in /home1/yh_739/.local/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.3.1)
Requirement already satisfied: bitsandbytes in /home1/yh_739/.local/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.42.0)
Requirement already satisfied: accelerate==0.31.0 in /home1/yh_739/.local/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.31.0)
Requirement already satisfied: datasets in /home1/yh_739/.local/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (2.20.0)
Requirement already satisfied: pandas in /home1/yh_739/.local/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (2.2.2)
Requirement already satisfied: numpy in /home1/yh_739/.local/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (2.0.0)
Requirement already satisfied: huggingface_hub in /home1/yh_739/.local/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (0.23.4)
Requirement already satisfied: packaging>=20.0 in /spack/conda/miniconda3/23.10.0/lib/python3.11/site-packages (from accelerate==0.31.0->-r requirements.txt (line 4)) (23.1)
Requirement already satisfied: psutil in /home1/yh_739/.local/lib/python3.11/site-packages (from accelerate==0.31.0->-r requirements.txt (line 4)) (6.0.0)
Requirement already satisfied: pyyaml in /home1/yh_739/.local/lib/python3.11/site-packages (from accelerate==0.31.0->-r requirements.txt (line 4)) (6.0.1)
Requirement already satisfied: safetensors>=0.3.1 in /home1/yh_739/.local/lib/python3.11/site-packages (from accelerate==0.31.0->-r requirements.txt (line 4)) (0.4.3)
Requirement already satisfied: filelock in /home1/yh_739/.local/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 1)) (3.15.3)
Requirement already satisfied: regex!=2019.12.17 in /home1/yh_739/.local/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 1)) (2024.5.15)
Requirement already satisfied: requests in /home1/yh_739/.local/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 1)) (2.32.3)
Requirement already satisfied: tokenizers<0.20,>=0.19 in /home1/yh_739/.local/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 1)) (0.19.1)
Requirement already satisfied: tqdm>=4.27 in /home1/yh_739/.local/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 1)) (4.66.4)
Requirement already satisfied: typing-extensions>=4.8.0 in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (4.12.2)
Requirement already satisfied: sympy in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (1.12.1)
Requirement already satisfied: networkx in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (3.3)
Requirement already satisfied: jinja2 in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (3.1.4)
Requirement already satisfied: fsspec in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (2024.5.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (2.20.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (12.1.105)
Requirement already satisfied: triton==2.3.1 in /home1/yh_739/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (2.3.1)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /home1/yh_739/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 2)) (12.5.40)
Requirement already satisfied: scipy in /home1/yh_739/.local/lib/python3.11/site-packages (from bitsandbytes->-r requirements.txt (line 3)) (1.13.1)
Requirement already satisfied: pyarrow>=15.0.0 in /home1/yh_739/.local/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (16.1.0)
Requirement already satisfied: pyarrow-hotfix in /home1/yh_739/.local/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (0.6)
Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home1/yh_739/.local/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (0.3.8)
Requirement already satisfied: xxhash in /home1/yh_739/.local/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (3.4.1)
Requirement already satisfied: multiprocess in /home1/yh_739/.local/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (0.70.16)
Requirement already satisfied: aiohttp in /home1/yh_739/.local/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (3.9.5)
Requirement already satisfied: python-dateutil>=2.8.2 in /home1/yh_739/.local/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 6)) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in /home1/yh_739/.local/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 6)) (2024.1)
Requirement already satisfied: tzdata>=2022.7 in /home1/yh_739/.local/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 6)) (2024.1)
Requirement already satisfied: aiosignal>=1.1.2 in /home1/yh_739/.local/lib/python3.11/site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.3.1)
Requirement already satisfied: attrs>=17.3.0 in /home1/yh_739/.local/lib/python3.11/site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (23.2.0)
Requirement already satisfied: frozenlist>=1.1.1 in /home1/yh_739/.local/lib/python3.11/site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.4.1)
Requirement already satisfied: multidict<7.0,>=4.5 in /home1/yh_739/.local/lib/python3.11/site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (6.0.5)
Requirement already satisfied: yarl<2.0,>=1.0 in /home1/yh_739/.local/lib/python3.11/site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.9.4)
Requirement already satisfied: six>=1.5 in /home1/yh_739/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 6)) (1.16.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /spack/conda/miniconda3/23.10.0/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 1)) (2.0.4)
Requirement already satisfied: idna<4,>=2.5 in /spack/conda/miniconda3/23.10.0/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 1)) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /spack/conda/miniconda3/23.10.0/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 1)) (1.26.18)
Requirement already satisfied: certifi>=2017.4.17 in /spack/conda/miniconda3/23.10.0/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 1)) (2023.11.17)
Requirement already satisfied: MarkupSafe>=2.0 in /home1/yh_739/.local/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 2)) (2.1.5)
Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home1/yh_739/.local/lib/python3.11/site-packages (from sympy->torch->-r requirements.txt (line 2)) (1.3.0)
Filter (num_proc=10):   0%|          | 0/496380 [00:00<?, ? examples/s]Filter (num_proc=10):   0%|          | 1000/496380 [00:01<09:43, 848.76 examples/s]Filter (num_proc=10):   1%|          | 5000/496380 [00:01<01:38, 5006.29 examples/s]Filter (num_proc=10):   2%|▏         | 9000/496380 [00:01<00:52, 9245.42 examples/s]Filter (num_proc=10):   2%|▏         | 12000/496380 [00:02<01:38, 4932.22 examples/s]Filter (num_proc=10):   3%|▎         | 16000/496380 [00:02<01:09, 6884.26 examples/s]Filter (num_proc=10):   4%|▎         | 18000/496380 [00:03<01:06, 7204.70 examples/s]Filter (num_proc=10):   4%|▍         | 20000/496380 [00:03<00:56, 8475.79 examples/s]Filter (num_proc=10):   4%|▍         | 22000/496380 [00:03<01:17, 6131.77 examples/s]Filter (num_proc=10):   5%|▍         | 24000/496380 [00:03<01:05, 7209.05 examples/s]Filter (num_proc=10):   5%|▌         | 26000/496380 [00:04<01:03, 7452.78 examples/s]Filter (num_proc=10):   6%|▌         | 28000/496380 [00:04<01:08, 6818.94 examples/s]Filter (num_proc=10):   6%|▌         | 31000/496380 [00:04<01:14, 6212.70 examples/s]Filter (num_proc=10):   7%|▋         | 33000/496380 [00:05<01:04, 7143.20 examples/s]Filter (num_proc=10):   7%|▋         | 36000/496380 [00:05<01:04, 7146.90 examples/s]Filter (num_proc=10):   7%|▋         | 37000/496380 [00:05<01:09, 6617.17 examples/s]Filter (num_proc=10):   8%|▊         | 38000/496380 [00:05<01:12, 6343.76 examples/s]Filter (num_proc=10):   8%|▊         | 40000/496380 [00:06<00:58, 7823.32 examples/s]Filter (num_proc=10):   8%|▊         | 41000/496380 [00:06<00:58, 7803.76 examples/s]Filter (num_proc=10):   9%|▊         | 43000/496380 [00:06<00:50, 9048.47 examples/s]Filter (num_proc=10):   9%|▉         | 46000/496380 [00:06<00:59, 7614.21 examples/s]Filter (num_proc=10):   9%|▉         | 47000/496380 [00:07<01:17, 5828.73 examples/s]Filter (num_proc=10):  10%|▉         | 48000/496380 [00:07<01:15, 5916.72 examples/s]Filter (num_proc=10):  10%|█         | 50000/496380 [00:07<00:59, 7542.36 examples/s]Filter (num_proc=10):  11%|█         | 54000/496380 [00:07<00:36, 12047.11 examples/s]Filter (num_proc=10):  11%|█▏        | 56000/496380 [00:08<01:00, 7279.38 examples/s] Filter (num_proc=10):  12%|█▏        | 58000/496380 [00:08<01:11, 6164.57 examples/s]Filter (num_proc=10):  12%|█▏        | 59000/496380 [00:08<01:15, 5818.87 examples/s]Filter (num_proc=10):  12%|█▏        | 62000/496380 [00:09<00:51, 8502.22 examples/s]Filter (num_proc=10):  13%|█▎        | 65000/496380 [00:09<00:39, 10841.87 examples/s]Filter (num_proc=10):  13%|█▎        | 67000/496380 [00:09<01:08, 6281.37 examples/s] Filter (num_proc=10):  14%|█▍        | 69000/496380 [00:10<00:58, 7352.07 examples/s]Filter (num_proc=10):  14%|█▍        | 71000/496380 [00:10<00:55, 7650.38 examples/s]Filter (num_proc=10):  15%|█▍        | 73000/496380 [00:10<00:51, 8272.05 examples/s]Filter (num_proc=10):  15%|█▌        | 75000/496380 [00:10<00:59, 7031.20 examples/s]Filter (num_proc=10):  16%|█▌        | 77000/496380 [00:11<01:00, 6940.91 examples/s]Filter (num_proc=10):  16%|█▌        | 78000/496380 [00:11<01:02, 6735.06 examples/s]Filter (num_proc=10):  16%|█▌        | 80000/496380 [00:11<00:51, 8161.17 examples/s]Filter (num_proc=10):  16%|█▋        | 81000/496380 [00:11<00:55, 7525.33 examples/s]Filter (num_proc=10):  17%|█▋        | 82000/496380 [00:11<01:01, 6752.86 examples/s]Filter (num_proc=10):  17%|█▋        | 85000/496380 [00:12<01:00, 6826.14 examples/s]Filter (num_proc=10):  18%|█▊        | 87000/496380 [00:12<00:59, 6937.08 examples/s]Filter (num_proc=10):  18%|█▊        | 88000/496380 [00:12<00:59, 6898.52 examples/s]Filter (num_proc=10):  18%|█▊        | 90000/496380 [00:12<00:46, 8686.35 examples/s]Filter (num_proc=10):  19%|█▊        | 92000/496380 [00:13<00:49, 8117.36 examples/s]Filter (num_proc=10):  19%|█▊        | 93000/496380 [00:13<00:48, 8351.54 examples/s]Filter (num_proc=10):  19%|█▉        | 95000/496380 [00:13<00:59, 6735.05 examples/s]Filter (num_proc=10):  20%|█▉        | 97000/496380 [00:13<00:47, 8475.64 examples/s]Filter (num_proc=10):  20%|█▉        | 99000/496380 [00:14<00:59, 6628.24 examples/s]Filter (num_proc=10):  20%|██        | 100000/496380 [00:14<00:58, 6782.37 examples/s]Filter (num_proc=10):  21%|██        | 102000/496380 [00:14<00:48, 8195.42 examples/s]Filter (num_proc=10):  21%|██        | 103000/496380 [00:14<00:55, 7067.38 examples/s]Filter (num_proc=10):  21%|██        | 105000/496380 [00:14<00:52, 7440.53 examples/s]Filter (num_proc=10):  21%|██▏       | 106000/496380 [00:15<01:03, 6164.85 examples/s]Filter (num_proc=10):  22%|██▏       | 109000/496380 [00:15<00:41, 9413.12 examples/s]Filter (num_proc=10):  22%|██▏       | 111000/496380 [00:15<00:51, 7542.39 examples/s]Filter (num_proc=10):  23%|██▎       | 112000/496380 [00:15<00:50, 7596.18 examples/s]Filter (num_proc=10):  23%|██▎       | 113000/496380 [00:16<00:59, 6470.32 examples/s]Filter (num_proc=10):  23%|██▎       | 115000/496380 [00:16<00:54, 7047.54 examples/s]Filter (num_proc=10):  24%|██▎       | 117000/496380 [00:16<00:49, 7737.26 examples/s]Filter (num_proc=10):  24%|██▍       | 119000/496380 [00:16<00:46, 8125.56 examples/s]Filter (num_proc=10):  24%|██▍       | 120000/496380 [00:17<01:03, 5971.11 examples/s]Filter (num_proc=10):  25%|██▍       | 122000/496380 [00:17<00:53, 6943.07 examples/s]Filter (num_proc=10):  25%|██▍       | 123000/496380 [00:17<00:54, 6831.79 examples/s]Filter (num_proc=10):  25%|██▍       | 124000/496380 [00:17<00:57, 6476.05 examples/s]Filter (num_proc=10):  26%|██▌       | 127000/496380 [00:17<00:41, 8815.96 examples/s]Filter (num_proc=10):  26%|██▌       | 129000/496380 [00:18<00:52, 6959.39 examples/s]Filter (num_proc=10):  27%|██▋       | 132000/496380 [00:18<00:58, 6248.00 examples/s]Filter (num_proc=10):  27%|██▋       | 135000/496380 [00:18<00:44, 8064.24 examples/s]Filter (num_proc=10):  28%|██▊       | 138000/496380 [00:19<00:35, 10102.44 examples/s]Filter (num_proc=10):  28%|██▊       | 140000/496380 [00:19<00:51, 6933.17 examples/s] Filter (num_proc=10):  29%|██▊       | 142000/496380 [00:20<00:56, 6233.82 examples/s]Filter (num_proc=10):  29%|██▉       | 143000/496380 [00:20<00:57, 6174.37 examples/s]Filter (num_proc=10):  30%|██▉       | 147000/496380 [00:20<00:36, 9623.02 examples/s]Filter (num_proc=10):  30%|███       | 149000/496380 [00:20<00:35, 9745.11 examples/s]Filter (num_proc=10):  30%|███       | 151000/496380 [00:21<00:52, 6541.39 examples/s]Filter (num_proc=10):  31%|███       | 152000/496380 [00:21<00:53, 6414.55 examples/s]Filter (num_proc=10):  31%|███       | 154000/496380 [00:21<00:44, 7768.03 examples/s]Filter (num_proc=10):  31%|███▏      | 156000/496380 [00:21<00:42, 7985.84 examples/s]Filter (num_proc=10):  32%|███▏      | 158000/496380 [00:21<00:35, 9510.92 examples/s]Filter (num_proc=10):  32%|███▏      | 160000/496380 [00:22<00:34, 9782.60 examples/s]Filter (num_proc=10):  33%|███▎      | 162000/496380 [00:22<01:00, 5544.38 examples/s]Filter (num_proc=10):  33%|███▎      | 165000/496380 [00:23<00:50, 6587.96 examples/s]Filter (num_proc=10):  33%|███▎      | 166000/496380 [00:23<00:48, 6776.06 examples/s]Filter (num_proc=10):  34%|███▍      | 168000/496380 [00:23<00:42, 7807.84 examples/s]Filter (num_proc=10):  34%|███▍      | 171000/496380 [00:23<00:40, 8061.14 examples/s]Filter (num_proc=10):  35%|███▍      | 172000/496380 [00:24<00:46, 7006.66 examples/s]Filter (num_proc=10):  35%|███▍      | 173000/496380 [00:24<00:55, 5863.42 examples/s]Filter (num_proc=10):  35%|███▌      | 175000/496380 [00:24<00:42, 7548.01 examples/s]Filter (num_proc=10):  36%|███▌      | 177000/496380 [00:24<00:36, 8670.69 examples/s]Filter (num_proc=10):  36%|███▌      | 179000/496380 [00:24<00:37, 8385.60 examples/s]Filter (num_proc=10):  36%|███▋      | 181000/496380 [00:25<00:36, 8641.22 examples/s]Filter (num_proc=10):  37%|███▋      | 182000/496380 [00:25<00:43, 7261.94 examples/s]Filter (num_proc=10):  37%|███▋      | 183000/496380 [00:25<00:48, 6476.11 examples/s]Filter (num_proc=10):  37%|███▋      | 184000/496380 [00:25<00:45, 6886.07 examples/s]Filter (num_proc=10):  37%|███▋      | 185000/496380 [00:25<00:53, 5836.19 examples/s]Filter (num_proc=10):  38%|███▊      | 188000/496380 [00:26<00:37, 8122.02 examples/s]Filter (num_proc=10):  38%|███▊      | 189000/496380 [00:26<00:44, 6847.16 examples/s]Filter (num_proc=10):  38%|███▊      | 191000/496380 [00:26<00:38, 7885.24 examples/s]Filter (num_proc=10):  39%|███▉      | 193000/496380 [00:26<00:44, 6789.18 examples/s]Filter (num_proc=10):  39%|███▉      | 195000/496380 [00:27<00:36, 8238.97 examples/s]Filter (num_proc=10):  39%|███▉      | 196000/496380 [00:27<00:46, 6448.39 examples/s]Filter (num_proc=10):  40%|████      | 199000/496380 [00:27<00:42, 7072.61 examples/s]Filter (num_proc=10):  40%|████      | 200000/496380 [00:27<00:42, 6987.52 examples/s]Filter (num_proc=10):  41%|████      | 202000/496380 [00:28<00:39, 7423.63 examples/s]Filter (num_proc=10):  41%|████      | 204000/496380 [00:28<00:31, 9247.66 examples/s]Filter (num_proc=10):  42%|████▏     | 206000/496380 [00:28<00:40, 7211.01 examples/s]Filter (num_proc=10):  42%|████▏     | 207000/496380 [00:28<00:41, 6917.76 examples/s]Filter (num_proc=10):  42%|████▏     | 208000/496380 [00:28<00:39, 7317.89 examples/s]Filter (num_proc=10):  42%|████▏     | 209000/496380 [00:29<00:54, 5277.02 examples/s]Filter (num_proc=10):  43%|████▎     | 212000/496380 [00:29<00:33, 8439.95 examples/s]Filter (num_proc=10):  43%|████▎     | 214000/496380 [00:29<00:31, 9107.64 examples/s]Filter (num_proc=10):  44%|████▎     | 216000/496380 [00:30<00:38, 7203.42 examples/s]Filter (num_proc=10):  44%|████▎     | 217000/496380 [00:30<00:48, 5787.23 examples/s]Filter (num_proc=10):  44%|████▍     | 218000/496380 [00:30<00:44, 6291.01 examples/s]Filter (num_proc=10):  44%|████▍     | 219000/496380 [00:30<00:42, 6590.45 examples/s]Filter (num_proc=10):  45%|████▍     | 222000/496380 [00:30<00:27, 9967.22 examples/s]Filter (num_proc=10):  45%|████▌     | 224000/496380 [00:30<00:26, 10176.65 examples/s]Filter (num_proc=10):  46%|████▌     | 226000/496380 [00:31<00:46, 5762.86 examples/s] Filter (num_proc=10):  46%|████▌     | 227000/496380 [00:31<00:50, 5379.46 examples/s]Filter (num_proc=10):  47%|████▋     | 231000/496380 [00:31<00:28, 9370.08 examples/s]Filter (num_proc=10):  47%|████▋     | 233000/496380 [00:32<00:31, 8359.63 examples/s]Filter (num_proc=10):  47%|████▋     | 235000/496380 [00:32<00:38, 6732.55 examples/s]Filter (num_proc=10):  48%|████▊     | 236000/496380 [00:32<00:43, 6048.46 examples/s]Filter (num_proc=10):  48%|████▊     | 240000/496380 [00:33<00:27, 9465.27 examples/s]Filter (num_proc=10):  49%|████▉     | 242000/496380 [00:33<00:33, 7666.97 examples/s]Filter (num_proc=10):  49%|████▉     | 244000/496380 [00:33<00:33, 7449.77 examples/s]Filter (num_proc=10):  50%|████▉     | 246000/496380 [00:34<00:31, 7852.06 examples/s]Filter (num_proc=10):  50%|████▉     | 248000/496380 [00:34<00:29, 8280.36 examples/s]Filter (num_proc=10):  50%|█████     | 250000/496380 [00:34<00:27, 9119.91 examples/s]Filter (num_proc=10):  51%|█████     | 252000/496380 [00:34<00:37, 6522.62 examples/s]Filter (num_proc=10):  51%|█████     | 254000/496380 [00:35<00:37, 6452.40 examples/s]Filter (num_proc=10):  51%|█████▏    | 255000/496380 [00:35<00:35, 6849.48 examples/s]Filter (num_proc=10):  52%|█████▏    | 259000/496380 [00:35<00:25, 9483.12 examples/s]Filter (num_proc=10):  53%|█████▎    | 261000/496380 [00:35<00:30, 7736.14 examples/s]Filter (num_proc=10):  53%|█████▎    | 262000/496380 [00:36<00:35, 6652.30 examples/s]Filter (num_proc=10):  53%|█████▎    | 264000/496380 [00:36<00:29, 7777.46 examples/s]Filter (num_proc=10):  54%|█████▎    | 266000/496380 [00:36<00:24, 9487.74 examples/s]Filter (num_proc=10):  54%|█████▍    | 268000/496380 [00:36<00:24, 9281.54 examples/s]Filter (num_proc=10):  54%|█████▍    | 270000/496380 [00:37<00:33, 6664.00 examples/s]Filter (num_proc=10):  55%|█████▍    | 271000/496380 [00:37<00:36, 6233.50 examples/s]Filter (num_proc=10):  55%|█████▌    | 274000/496380 [00:37<00:28, 7752.09 examples/s]Filter (num_proc=10):  56%|█████▌    | 276000/496380 [00:38<00:31, 7040.01 examples/s]Filter (num_proc=10):  56%|█████▌    | 278000/496380 [00:38<00:26, 8389.19 examples/s]Filter (num_proc=10):  56%|█████▋    | 280000/496380 [00:38<00:28, 7625.61 examples/s]Filter (num_proc=10):  57%|█████▋    | 281000/496380 [00:38<00:29, 7273.72 examples/s]Filter (num_proc=10):  57%|█████▋    | 283000/496380 [00:39<00:31, 6710.51 examples/s]Filter (num_proc=10):  58%|█████▊    | 286000/496380 [00:39<00:29, 7229.49 examples/s]Filter (num_proc=10):  58%|█████▊    | 288000/496380 [00:39<00:27, 7494.69 examples/s]Filter (num_proc=10):  58%|█████▊    | 290000/496380 [00:39<00:23, 8723.65 examples/s]Filter (num_proc=10):  59%|█████▉    | 292000/496380 [00:40<00:23, 8602.14 examples/s]Filter (num_proc=10):  59%|█████▉    | 293000/496380 [00:40<00:26, 7763.38 examples/s]Filter (num_proc=10):  59%|█████▉    | 294000/496380 [00:40<00:29, 6868.29 examples/s]Filter (num_proc=10):  59%|█████▉    | 295000/496380 [00:40<00:29, 6931.08 examples/s]Filter (num_proc=10):  60%|█████▉    | 296000/496380 [00:40<00:29, 6685.49 examples/s]Filter (num_proc=10):  60%|██████    | 298000/496380 [00:41<00:30, 6490.62 examples/s]Filter (num_proc=10):  60%|██████    | 300000/496380 [00:41<00:26, 7502.50 examples/s]Filter (num_proc=10):  61%|██████    | 301000/496380 [00:41<00:26, 7500.73 examples/s]Filter (num_proc=10):  61%|██████    | 303000/496380 [00:41<00:20, 9567.21 examples/s]Filter (num_proc=10):  61%|██████▏   | 305000/496380 [00:41<00:29, 6414.46 examples/s]Filter (num_proc=10):  62%|██████▏   | 306000/496380 [00:42<00:28, 6616.65 examples/s]Filter (num_proc=10):  62%|██████▏   | 308000/496380 [00:42<00:23, 8165.12 examples/s]Filter (num_proc=10):  62%|██████▏   | 310000/496380 [00:42<00:25, 7239.09 examples/s]Filter (num_proc=10):  63%|██████▎   | 311000/496380 [00:42<00:24, 7529.91 examples/s]Filter (num_proc=10):  63%|██████▎   | 312000/496380 [00:42<00:24, 7509.94 examples/s]Filter (num_proc=10):  63%|██████▎   | 313000/496380 [00:42<00:23, 7877.65 examples/s]Filter (num_proc=10):  63%|██████▎   | 314000/496380 [00:43<00:25, 7224.03 examples/s]Filter (num_proc=10):  64%|██████▎   | 316000/496380 [00:43<00:27, 6500.97 examples/s]Filter (num_proc=10):  64%|██████▍   | 317000/496380 [00:43<00:25, 6966.99 examples/s]Filter (num_proc=10):  64%|██████▍   | 319000/496380 [00:43<00:19, 8879.30 examples/s]Filter (num_proc=10):  65%|██████▍   | 321000/496380 [00:43<00:20, 8446.84 examples/s]Filter (num_proc=10):  65%|██████▍   | 322000/496380 [00:44<00:25, 6832.39 examples/s]Filter (num_proc=10):  65%|██████▌   | 323000/496380 [00:44<00:26, 6458.92 examples/s]Filter (num_proc=10):  65%|██████▌   | 325000/496380 [00:44<00:24, 6860.87 examples/s]Filter (num_proc=10):  66%|██████▌   | 327000/496380 [00:44<00:20, 8131.38 examples/s]Filter (num_proc=10):  66%|██████▌   | 328000/496380 [00:45<00:23, 7236.39 examples/s]Filter (num_proc=10):  66%|██████▋   | 330000/496380 [00:45<00:21, 7845.56 examples/s]Filter (num_proc=10):  67%|██████▋   | 331000/496380 [00:45<00:21, 7871.11 examples/s]Filter (num_proc=10):  67%|██████▋   | 332000/496380 [00:45<00:23, 7075.68 examples/s]Filter (num_proc=10):  67%|██████▋   | 334000/496380 [00:45<00:21, 7454.72 examples/s]Filter (num_proc=10):  67%|██████▋   | 335000/496380 [00:46<00:23, 6764.80 examples/s]Filter (num_proc=10):  68%|██████▊   | 337000/496380 [00:46<00:19, 8184.86 examples/s]Filter (num_proc=10):  68%|██████▊   | 339000/496380 [00:46<00:21, 7253.91 examples/s]Filter (num_proc=10):  68%|██████▊   | 340000/496380 [00:46<00:21, 7384.28 examples/s]Filter (num_proc=10):  69%|██████▊   | 341000/496380 [00:46<00:21, 7172.85 examples/s]Filter (num_proc=10):  69%|██████▉   | 343000/496380 [00:46<00:19, 7952.74 examples/s]Filter (num_proc=10):  69%|██████▉   | 344000/496380 [00:47<00:24, 6127.77 examples/s]Filter (num_proc=10):  70%|██████▉   | 347000/496380 [00:47<00:15, 9400.69 examples/s]Filter (num_proc=10):  70%|███████   | 349000/496380 [00:47<00:22, 6637.38 examples/s]Filter (num_proc=10):  71%|███████   | 351000/496380 [00:48<00:20, 7053.88 examples/s]Filter (num_proc=10):  71%|███████   | 352000/496380 [00:48<00:19, 7368.96 examples/s]Filter (num_proc=10):  71%|███████▏  | 354000/496380 [00:48<00:20, 6930.96 examples/s]Filter (num_proc=10):  72%|███████▏  | 357000/496380 [00:48<00:15, 9287.11 examples/s]Filter (num_proc=10):  72%|███████▏  | 359000/496380 [00:49<00:19, 7217.25 examples/s]Filter (num_proc=10):  73%|███████▎  | 361000/496380 [00:49<00:17, 7526.87 examples/s]Filter (num_proc=10):  73%|███████▎  | 363000/496380 [00:49<00:20, 6622.83 examples/s]Filter (num_proc=10):  74%|███████▎  | 366000/496380 [00:49<00:14, 9301.00 examples/s]Filter (num_proc=10):  74%|███████▍  | 368000/496380 [00:50<00:18, 6772.73 examples/s]Filter (num_proc=10):  75%|███████▍  | 370000/496380 [00:50<00:20, 6227.81 examples/s]Filter (num_proc=10):  75%|███████▍  | 372000/496380 [00:50<00:16, 7447.69 examples/s]Filter (num_proc=10):  75%|███████▌  | 374000/496380 [00:51<00:14, 8581.55 examples/s]Filter (num_proc=10):  76%|███████▌  | 376000/496380 [00:51<00:14, 8195.76 examples/s]Filter (num_proc=10):  76%|███████▌  | 378000/496380 [00:51<00:17, 6790.87 examples/s]Filter (num_proc=10):  77%|███████▋  | 380000/496380 [00:52<00:17, 6580.83 examples/s]Filter (num_proc=10):  77%|███████▋  | 381000/496380 [00:52<00:16, 6891.21 examples/s]Filter (num_proc=10):  77%|███████▋  | 384000/496380 [00:52<00:11, 10023.18 examples/s]Filter (num_proc=10):  78%|███████▊  | 386000/496380 [00:52<00:16, 6519.90 examples/s] Filter (num_proc=10):  78%|███████▊  | 388000/496380 [00:53<00:14, 7416.73 examples/s]Filter (num_proc=10):  79%|███████▊  | 390000/496380 [00:53<00:17, 6136.72 examples/s]Filter (num_proc=10):  79%|███████▉  | 393000/496380 [00:53<00:13, 7589.07 examples/s]Filter (num_proc=10):  80%|███████▉  | 395000/496380 [00:53<00:11, 8870.34 examples/s]Filter (num_proc=10):  80%|███████▉  | 397000/496380 [00:54<00:16, 6195.15 examples/s]Filter (num_proc=10):  80%|████████  | 398000/496380 [00:54<00:17, 5640.35 examples/s]Filter (num_proc=10):  81%|████████  | 401000/496380 [00:54<00:11, 8389.83 examples/s]Filter (num_proc=10):  81%|████████  | 403000/496380 [00:54<00:09, 9908.99 examples/s]Filter (num_proc=10):  82%|████████▏ | 405000/496380 [00:55<00:11, 7750.99 examples/s]Filter (num_proc=10):  82%|████████▏ | 407000/496380 [00:55<00:15, 5755.67 examples/s]Filter (num_proc=10):  82%|████████▏ | 408000/496380 [00:56<00:14, 6085.01 examples/s]Filter (num_proc=10):  83%|████████▎ | 411000/496380 [00:56<00:11, 7608.79 examples/s]Filter (num_proc=10):  83%|████████▎ | 412000/496380 [00:56<00:11, 7147.24 examples/s]Filter (num_proc=10):  83%|████████▎ | 413000/496380 [00:56<00:11, 7210.94 examples/s]Filter (num_proc=10):  84%|████████▎ | 415000/496380 [00:57<00:12, 6549.78 examples/s]Filter (num_proc=10):  84%|████████▍ | 416000/496380 [00:57<00:13, 5957.10 examples/s]Filter (num_proc=10):  84%|████████▍ | 418000/496380 [00:57<00:12, 6222.08 examples/s]Filter (num_proc=10):  85%|████████▍ | 421000/496380 [00:57<00:08, 8688.94 examples/s]Filter (num_proc=10):  85%|████████▌ | 422000/496380 [00:57<00:08, 8850.64 examples/s]Filter (num_proc=10):  85%|████████▌ | 424000/496380 [00:57<00:07, 9523.35 examples/s]Filter (num_proc=10):  86%|████████▌ | 426000/496380 [00:58<00:12, 5744.92 examples/s]Filter (num_proc=10):  86%|████████▌ | 428000/496380 [00:58<00:10, 6648.04 examples/s]Filter (num_proc=10):  87%|████████▋ | 430000/496380 [00:59<00:08, 7454.13 examples/s]Filter (num_proc=10):  87%|████████▋ | 432000/496380 [00:59<00:07, 9057.93 examples/s]Filter (num_proc=10):  87%|████████▋ | 434000/496380 [00:59<00:09, 6639.71 examples/s]Filter (num_proc=10):  88%|████████▊ | 435000/496380 [00:59<00:11, 5391.85 examples/s]Filter (num_proc=10):  88%|████████▊ | 436000/496380 [01:00<00:10, 5947.65 examples/s]Filter (num_proc=10):  88%|████████▊ | 439000/496380 [01:00<00:07, 8130.01 examples/s]Filter (num_proc=10):  89%|████████▉ | 441000/496380 [01:00<00:06, 8950.69 examples/s]Filter (num_proc=10):  89%|████████▉ | 443000/496380 [01:00<00:06, 8584.77 examples/s]Filter (num_proc=10):  89%|████████▉ | 444000/496380 [01:01<00:09, 5771.85 examples/s]Filter (num_proc=10):  90%|████████▉ | 446000/496380 [01:01<00:07, 7113.59 examples/s]Filter (num_proc=10):  90%|█████████ | 448000/496380 [01:01<00:07, 6471.91 examples/s]Filter (num_proc=10):  91%|█████████ | 452000/496380 [01:01<00:04, 9658.21 examples/s]Filter (num_proc=10):  91%|█████████▏| 454000/496380 [01:02<00:06, 7061.27 examples/s]Filter (num_proc=10):  92%|█████████▏| 456000/496380 [01:02<00:06, 6624.03 examples/s]Filter (num_proc=10):  92%|█████████▏| 458000/496380 [01:02<00:04, 7870.83 examples/s]Filter (num_proc=10):  93%|█████████▎| 460000/496380 [01:03<00:04, 7631.87 examples/s]Filter (num_proc=10):  93%|█████████▎| 461000/496380 [01:03<00:04, 7890.87 examples/s]Filter (num_proc=10):  93%|█████████▎| 462638/496380 [01:03<00:04, 8093.20 examples/s]Filter (num_proc=10):  93%|█████████▎| 463638/496380 [01:03<00:05, 6277.17 examples/s]Filter (num_proc=10):  94%|█████████▍| 465638/496380 [01:03<00:04, 6893.73 examples/s]Filter (num_proc=10):  94%|█████████▍| 467276/496380 [01:04<00:04, 6769.11 examples/s]Filter (num_proc=10):  94%|█████████▍| 468276/496380 [01:04<00:04, 6591.58 examples/s]Filter (num_proc=10):  95%|█████████▍| 470276/496380 [01:04<00:03, 8651.72 examples/s]Filter (num_proc=10):  95%|█████████▌| 472914/496380 [01:04<00:03, 6864.32 examples/s]Filter (num_proc=10):  96%|█████████▌| 474552/496380 [01:05<00:03, 6755.48 examples/s]Filter (num_proc=10):  96%|█████████▌| 476190/496380 [01:05<00:03, 5634.11 examples/s]Filter (num_proc=10):  96%|█████████▌| 477190/496380 [01:05<00:03, 5310.79 examples/s]Filter (num_proc=10):  97%|█████████▋| 479828/496380 [01:06<00:03, 4820.24 examples/s]Filter (num_proc=10):  97%|█████████▋| 480828/496380 [01:06<00:03, 4073.64 examples/s]Filter (num_proc=10):  97%|█████████▋| 481828/496380 [01:07<00:04, 3107.97 examples/s]Filter (num_proc=10):  97%|█████████▋| 483828/496380 [01:07<00:03, 3933.73 examples/s]Filter (num_proc=10):  98%|█████████▊| 484828/496380 [01:08<00:03, 3781.16 examples/s]Filter (num_proc=10):  98%|█████████▊| 485828/496380 [01:08<00:03, 2828.80 examples/s]Filter (num_proc=10):  98%|█████████▊| 486828/496380 [01:08<00:02, 3292.10 examples/s]Filter (num_proc=10):  98%|█████████▊| 487828/496380 [01:09<00:02, 3316.62 examples/s]Filter (num_proc=10):  99%|█████████▊| 489466/496380 [01:09<00:02, 3331.27 examples/s]Filter (num_proc=10):  99%|█████████▉| 490466/496380 [01:10<00:02, 2944.74 examples/s]Filter (num_proc=10):  99%|█████████▉| 491466/496380 [01:10<00:01, 2985.44 examples/s]Filter (num_proc=10):  99%|█████████▉| 492466/496380 [01:10<00:01, 3331.08 examples/s]Filter (num_proc=10):  99%|█████████▉| 493466/496380 [01:11<00:01, 2457.38 examples/s]Filter (num_proc=10): 100%|█████████▉| 495742/496380 [01:12<00:00, 2069.36 examples/s]Filter (num_proc=10): 100%|██████████| 496380/496380 [01:13<00:00, 1672.18 examples/s]Filter (num_proc=10): 100%|██████████| 496380/496380 [01:13<00:00, 6753.89 examples/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Downloading shards:   0%|          | 0/30 [00:00<?, ?it/s]Downloading shards:   7%|▋         | 2/30 [00:00<00:02, 10.65it/s]Downloading shards:  13%|█▎        | 4/30 [00:00<00:02, 10.04it/s]Downloading shards:  20%|██        | 6/30 [00:00<00:02, 10.33it/s]Downloading shards:  27%|██▋       | 8/30 [00:00<00:02, 10.43it/s]Downloading shards:  33%|███▎      | 10/30 [00:00<00:01, 10.42it/s]Downloading shards:  40%|████      | 12/30 [00:01<00:01, 10.49it/s]Downloading shards:  47%|████▋     | 14/30 [00:01<00:01, 10.58it/s]Downloading shards:  53%|█████▎    | 16/30 [00:01<00:01, 10.52it/s]Downloading shards:  60%|██████    | 18/30 [00:01<00:01, 10.36it/s]Downloading shards:  67%|██████▋   | 20/30 [00:01<00:00, 10.40it/s]Downloading shards:  73%|███████▎  | 22/30 [00:02<00:00, 10.22it/s]Downloading shards:  80%|████████  | 24/30 [00:02<00:00, 10.14it/s]Downloading shards:  87%|████████▋ | 26/30 [00:02<00:00, 10.13it/s]Downloading shards:  93%|█████████▎| 28/30 [00:02<00:00,  7.92it/s]Downloading shards: 100%|██████████| 30/30 [00:03<00:00,  8.63it/s]Downloading shards: 100%|██████████| 30/30 [00:03<00:00,  9.72it/s]
Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/30 [00:09<04:31,  9.38s/it]Loading checkpoint shards:   7%|▋         | 2/30 [00:19<04:37,  9.92s/it]Loading checkpoint shards:  10%|█         | 3/30 [00:29<04:29,  9.98s/it]Loading checkpoint shards:  13%|█▎        | 4/30 [00:41<04:40, 10.79s/it]Loading checkpoint shards:  17%|█▋        | 5/30 [00:51<04:21, 10.46s/it]Loading checkpoint shards:  20%|██        | 6/30 [01:08<05:04, 12.70s/it]Loading checkpoint shards:  23%|██▎       | 7/30 [01:18<04:29, 11.72s/it]Loading checkpoint shards:  27%|██▋       | 8/30 [01:32<04:31, 12.35s/it]Loading checkpoint shards:  30%|███       | 9/30 [01:41<04:01, 11.52s/it]Loading checkpoint shards:  33%|███▎      | 10/30 [01:50<03:31, 10.59s/it]Loading checkpoint shards:  37%|███▋      | 11/30 [02:02<03:29, 11.02s/it]Loading checkpoint shards:  40%|████      | 12/30 [02:19<03:50, 12.81s/it]Loading checkpoint shards:  43%|████▎     | 13/30 [02:31<03:33, 12.56s/it]Loading checkpoint shards:  47%|████▋     | 14/30 [02:40<03:06, 11.64s/it]Loading checkpoint shards:  50%|█████     | 15/30 [02:51<02:50, 11.37s/it]Loading checkpoint shards:  53%|█████▎    | 16/30 [03:02<02:37, 11.24s/it]Loading checkpoint shards:  57%|█████▋    | 17/30 [03:10<02:12, 10.22s/it]Loading checkpoint shards:  60%|██████    | 18/30 [03:11<01:29,  7.47s/it]Loading checkpoint shards:  63%|██████▎   | 19/30 [03:12<01:00,  5.49s/it]Loading checkpoint shards:  67%|██████▋   | 20/30 [03:12<00:40,  4.07s/it]Loading checkpoint shards:  70%|███████   | 21/30 [03:14<00:29,  3.26s/it]Loading checkpoint shards:  73%|███████▎  | 22/30 [03:15<00:20,  2.61s/it]Loading checkpoint shards:  77%|███████▋  | 23/30 [03:17<00:16,  2.42s/it]Loading checkpoint shards:  80%|████████  | 24/30 [03:19<00:14,  2.47s/it]Loading checkpoint shards:  83%|████████▎ | 25/30 [03:21<00:10,  2.14s/it]Loading checkpoint shards:  87%|████████▋ | 26/30 [03:22<00:07,  1.83s/it]Loading checkpoint shards:  90%|█████████ | 27/30 [03:23<00:05,  1.69s/it]Loading checkpoint shards:  93%|█████████▎| 28/30 [03:25<00:03,  1.58s/it]Loading checkpoint shards:  97%|█████████▋| 29/30 [03:25<00:01,  1.35s/it]Loading checkpoint shards: 100%|██████████| 30/30 [03:26<00:00,  1.00s/it]Loading checkpoint shards: 100%|██████████| 30/30 [03:26<00:00,  6.87s/it]
WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.
Traceback (most recent call last):
  File "/project/jonmay_231/spangher/Projects/conditional-information-retrieval/data_script.py", line 115, in <module>
    response = infer(model, tokenizer, message)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/jonmay_231/spangher/Projects/conditional-information-retrieval/data_script.py", line 40, in infer
    outputs = model.generate(
              ^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/transformers/generation/utils.py", line 1758, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/transformers/generation/utils.py", line 2397, in _sample
    outputs = self(
              ^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 166, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 166, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 166, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 166, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home1/yh_739/.local/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 232.00 MiB. GPU  has a total capacity of 39.39 GiB of which 219.94 MiB is free. Including non-PyTorch memory, this process has 39.17 GiB memory in use. Of the allocated memory 38.47 GiB is allocated by PyTorch, and 208.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
